{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2da9a513-3311-4ca8-bdde-2f8396b20b39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Processing page 1 jobs:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Processing page 1 jobs:   2%|▏         | 1/50 [00:00<00:37,  1.31it/s]\u001b[A\n",
      "Processing page 1 jobs:   4%|▍         | 2/50 [00:01<00:38,  1.23it/s]\u001b[A\n",
      "Processing page 1 jobs:   6%|▌         | 3/50 [00:02<00:36,  1.29it/s]\u001b[A\n",
      "Processing page 1 jobs:   8%|▊         | 4/50 [00:03<00:35,  1.29it/s]\u001b[A\n",
      "Processing page 1 jobs:  10%|█         | 5/50 [00:03<00:33,  1.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  12%|█▏        | 6/50 [00:04<00:32,  1.37it/s]\u001b[A\n",
      "Processing page 1 jobs:  14%|█▍        | 7/50 [00:05<00:30,  1.39it/s]\u001b[A\n",
      "Processing page 1 jobs:  16%|█▌        | 8/50 [00:05<00:30,  1.39it/s]\u001b[A\n",
      "Processing page 1 jobs:  18%|█▊        | 9/50 [00:06<00:30,  1.36it/s]\u001b[A\n",
      "Processing page 1 jobs:  20%|██        | 10/50 [00:07<00:28,  1.38it/s]\u001b[A\n",
      "Processing page 1 jobs:  22%|██▏       | 11/50 [00:08<00:28,  1.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  24%|██▍       | 12/50 [00:08<00:28,  1.33it/s]\u001b[A\n",
      "Processing page 1 jobs:  26%|██▌       | 13/50 [00:09<00:27,  1.37it/s]\u001b[A\n",
      "Processing page 1 jobs:  28%|██▊       | 14/50 [00:10<00:26,  1.34it/s]\u001b[A\n",
      "Processing page 1 jobs:  30%|███       | 15/50 [00:11<00:26,  1.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  32%|███▏      | 16/50 [00:12<00:26,  1.28it/s]\u001b[A\n",
      "Processing page 1 jobs:  34%|███▍      | 17/50 [00:12<00:25,  1.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  36%|███▌      | 18/50 [00:13<00:24,  1.33it/s]\u001b[A\n",
      "Processing page 1 jobs:  38%|███▊      | 19/50 [00:14<00:22,  1.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  40%|████      | 20/50 [00:14<00:22,  1.33it/s]\u001b[A\n",
      "Processing page 1 jobs:  42%|████▏     | 21/50 [00:15<00:23,  1.23it/s]\u001b[A\n",
      "Processing page 1 jobs:  44%|████▍     | 22/50 [00:16<00:22,  1.25it/s]\u001b[A\n",
      "Processing page 1 jobs:  46%|████▌     | 23/50 [00:17<00:20,  1.34it/s]\u001b[A\n",
      "Processing page 1 jobs:  48%|████▊     | 24/50 [00:18<00:19,  1.33it/s]\u001b[A\n",
      "Processing page 1 jobs:  50%|█████     | 25/50 [00:18<00:19,  1.29it/s]\u001b[A\n",
      "Processing page 1 jobs:  52%|█████▏    | 26/50 [00:19<00:18,  1.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  54%|█████▍    | 27/50 [00:20<00:17,  1.28it/s]\u001b[A\n",
      "Processing page 1 jobs:  56%|█████▌    | 28/50 [00:21<00:16,  1.31it/s]\u001b[A\n",
      "Processing page 1 jobs:  58%|█████▊    | 29/50 [00:21<00:15,  1.38it/s]\u001b[A\n",
      "Processing page 1 jobs:  60%|██████    | 30/50 [00:22<00:14,  1.34it/s]\u001b[A\n",
      "Processing page 1 jobs:  62%|██████▏   | 31/50 [00:23<00:13,  1.38it/s]\u001b[A\n",
      "Processing page 1 jobs:  64%|██████▍   | 32/50 [00:23<00:12,  1.42it/s]\u001b[A\n",
      "Processing page 1 jobs:  66%|██████▌   | 33/50 [00:24<00:10,  1.67it/s]\u001b[A\n",
      "Processing page 1 jobs:  68%|██████▊   | 34/50 [00:24<00:08,  1.85it/s]\u001b[A\n",
      "Processing page 1 jobs:  70%|███████   | 35/50 [00:25<00:07,  2.03it/s]\u001b[A\n",
      "Processing page 1 jobs:  72%|███████▏  | 36/50 [00:25<00:06,  2.15it/s]\u001b[A\n",
      "Processing page 1 jobs:  74%|███████▍  | 37/50 [00:26<00:06,  1.98it/s]\u001b[A\n",
      "Processing page 1 jobs:  76%|███████▌  | 38/50 [00:26<00:05,  2.15it/s]\u001b[A\n",
      "Processing page 1 jobs:  78%|███████▊  | 39/50 [00:26<00:05,  2.17it/s]\u001b[A\n",
      "Processing page 1 jobs:  80%|████████  | 40/50 [00:27<00:04,  2.18it/s]\u001b[A\n",
      "Processing page 1 jobs:  82%|████████▏ | 41/50 [00:27<00:03,  2.32it/s]\u001b[A\n",
      "Processing page 1 jobs:  84%|████████▍ | 42/50 [00:28<00:03,  2.34it/s]\u001b[A\n",
      "Processing page 1 jobs:  86%|████████▌ | 43/50 [00:28<00:02,  2.36it/s]\u001b[A\n",
      "Processing page 1 jobs:  88%|████████▊ | 44/50 [00:29<00:02,  2.25it/s]\u001b[A\n",
      "Processing page 1 jobs:  90%|█████████ | 45/50 [00:29<00:02,  2.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  92%|█████████▏| 46/50 [00:29<00:01,  2.37it/s]\u001b[A\n",
      "Processing page 1 jobs:  94%|█████████▍| 47/50 [00:30<00:01,  2.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  96%|█████████▌| 48/50 [00:30<00:00,  2.44it/s]\u001b[A\n",
      "Processing page 1 jobs:  98%|█████████▊| 49/50 [00:31<00:00,  2.49it/s]\u001b[A\n",
      "Processing page 1 jobs: 100%|██████████| 50/50 [00:31<00:00,  2.55it/s]\u001b[A\n",
      "Processing pages:  50%|█████     | 1/2 [00:32<00:32, 32.53s/it]        \u001b[A\n",
      "Processing page 2 jobs:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Processing page 2 jobs:   2%|▏         | 1/50 [00:00<00:31,  1.56it/s]\u001b[A\n",
      "Processing page 2 jobs:   4%|▍         | 2/50 [00:01<00:28,  1.70it/s]\u001b[A\n",
      "Processing page 2 jobs:   6%|▌         | 3/50 [00:01<00:30,  1.53it/s]\u001b[A\n",
      "Processing page 2 jobs:   8%|▊         | 4/50 [00:02<00:29,  1.57it/s]\u001b[A\n",
      "Processing page 2 jobs:  10%|█         | 5/50 [00:03<00:29,  1.51it/s]\u001b[A\n",
      "Processing page 2 jobs:  12%|█▏        | 6/50 [00:04<00:31,  1.41it/s]\u001b[A\n",
      "Processing page 2 jobs:  14%|█▍        | 7/50 [00:04<00:28,  1.53it/s]\u001b[A\n",
      "Processing page 2 jobs:  16%|█▌        | 8/50 [00:05<00:26,  1.57it/s]\u001b[A\n",
      "Processing page 2 jobs:  18%|█▊        | 9/50 [00:05<00:26,  1.56it/s]\u001b[A\n",
      "Processing page 2 jobs:  20%|██        | 10/50 [00:06<00:26,  1.50it/s]\u001b[A\n",
      "Processing page 2 jobs:  22%|██▏       | 11/50 [00:07<00:24,  1.57it/s]\u001b[A\n",
      "Processing page 2 jobs:  24%|██▍       | 12/50 [00:07<00:23,  1.59it/s]\u001b[A\n",
      "Processing page 2 jobs:  26%|██▌       | 13/50 [00:08<00:23,  1.59it/s]\u001b[A\n",
      "Processing page 2 jobs:  28%|██▊       | 14/50 [00:09<00:23,  1.55it/s]\u001b[A\n",
      "Processing page 2 jobs:  30%|███       | 15/50 [00:09<00:21,  1.63it/s]\u001b[A\n",
      "Processing page 2 jobs:  32%|███▏      | 16/50 [00:10<00:19,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  34%|███▍      | 17/50 [00:10<00:19,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs:  36%|███▌      | 18/50 [00:11<00:20,  1.56it/s]\u001b[A\n",
      "Processing page 2 jobs:  38%|███▊      | 19/50 [00:12<00:19,  1.56it/s]\u001b[A\n",
      "Processing page 2 jobs:  40%|████      | 20/50 [00:13<00:22,  1.35it/s]\u001b[A\n",
      "Processing page 2 jobs:  42%|████▏     | 21/50 [00:13<00:20,  1.43it/s]\u001b[A\n",
      "Processing page 2 jobs:  44%|████▍     | 22/50 [00:14<00:19,  1.41it/s]\u001b[A\n",
      "Processing page 2 jobs:  46%|████▌     | 23/50 [00:14<00:17,  1.52it/s]\u001b[A\n",
      "Processing page 2 jobs:  48%|████▊     | 24/50 [00:15<00:16,  1.58it/s]\u001b[A\n",
      "Processing page 2 jobs:  50%|█████     | 25/50 [00:16<00:15,  1.60it/s]\u001b[A\n",
      "Processing page 2 jobs:  52%|█████▏    | 26/50 [00:16<00:15,  1.51it/s]\u001b[A\n",
      "Processing page 2 jobs:  54%|█████▍    | 27/50 [00:17<00:15,  1.49it/s]\u001b[A\n",
      "Processing page 2 jobs:  56%|█████▌    | 28/50 [00:18<00:14,  1.52it/s]\u001b[A\n",
      "Processing page 2 jobs:  58%|█████▊    | 29/50 [00:18<00:12,  1.65it/s]\u001b[A\n",
      "Processing page 2 jobs:  60%|██████    | 30/50 [00:19<00:13,  1.51it/s]\u001b[A\n",
      "Processing page 2 jobs:  62%|██████▏   | 31/50 [00:20<00:12,  1.51it/s]\u001b[A\n",
      "Processing page 2 jobs:  64%|██████▍   | 32/50 [00:20<00:11,  1.55it/s]\u001b[A\n",
      "Processing page 2 jobs:  66%|██████▌   | 33/50 [00:21<00:11,  1.50it/s]\u001b[A\n",
      "Processing page 2 jobs:  68%|██████▊   | 34/50 [00:22<00:10,  1.50it/s]\u001b[A\n",
      "Processing page 2 jobs:  70%|███████   | 35/50 [00:22<00:10,  1.45it/s]\u001b[A\n",
      "Processing page 2 jobs:  72%|███████▏  | 36/50 [00:23<00:09,  1.49it/s]\u001b[A\n",
      "Processing page 2 jobs:  74%|███████▍  | 37/50 [00:24<00:08,  1.60it/s]\u001b[A\n",
      "Processing page 2 jobs:  76%|███████▌  | 38/50 [00:24<00:08,  1.44it/s]\u001b[A\n",
      "Processing page 2 jobs:  78%|███████▊  | 39/50 [00:25<00:07,  1.51it/s]\u001b[A\n",
      "Processing page 2 jobs:  80%|████████  | 40/50 [00:26<00:06,  1.55it/s]\u001b[A\n",
      "Processing page 2 jobs:  82%|████████▏ | 41/50 [00:26<00:05,  1.65it/s]\u001b[A\n",
      "Processing page 2 jobs:  84%|████████▍ | 42/50 [00:27<00:05,  1.55it/s]\u001b[A\n",
      "Processing page 2 jobs:  86%|████████▌ | 43/50 [00:27<00:04,  1.58it/s]\u001b[A\n",
      "Processing page 2 jobs:  88%|████████▊ | 44/50 [00:29<00:04,  1.30it/s]\u001b[A\n",
      "Processing page 2 jobs:  90%|█████████ | 45/50 [00:29<00:03,  1.37it/s]\u001b[A\n",
      "Processing page 2 jobs:  92%|█████████▏| 46/50 [00:30<00:02,  1.50it/s]\u001b[A\n",
      "Processing page 2 jobs:  94%|█████████▍| 47/50 [00:30<00:01,  1.54it/s]\u001b[A\n",
      "Processing page 2 jobs:  96%|█████████▌| 48/50 [00:31<00:01,  1.48it/s]\u001b[A\n",
      "Processing page 2 jobs:  98%|█████████▊| 49/50 [00:32<00:00,  1.59it/s]\u001b[A\n",
      "Processing page 2 jobs: 100%|██████████| 50/50 [00:32<00:00,  1.62it/s]\u001b[A\n",
      "Processing pages: 100%|██████████| 2/2 [01:07<00:00, 33.65s/it]        \u001b[A\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# データを保存するリスト\n",
    "job_title = []\n",
    "unit_price = []\n",
    "required_experience = []\n",
    "details_page_link = []\n",
    "representative_name = []\n",
    "headquarters_locations = []\n",
    "industry = []\n",
    "contact_number = []\n",
    "company_info_link = []\n",
    "all_data = []\n",
    "\n",
    "# ページ番号を1から96までループ\n",
    "for page_number in tqdm(range(1, 3), desc=\"Processing pages\"):\n",
    "    try:\n",
    "        url = f'https://next.rikunabi.com/rnc/docs/cp_s00700.jsp?page={page_number}&cur=ACgAAQAoAAAAAAAAAAAAAAACMT4N4gECAQkUBgU6vVJcMq7CpmpPjbzo3HJe4dF7UXdwgM%2BXoqqxn4oQb50yRo6ag3iAKyyeqyFDcEzcwkGZDsn8prbqAeX62tWArTu1z3hoh%2FE%3D&cur_p=2&occupation_cd=EHPW9&wrk_plc_long_cd=0313113103&wrk_plc_long_cd=0313113105&wrk_plc_long_cd=0313113106&wrk_plc_long_cd=0313113107&wrk_plc_long_cd=0313113108&wrk_plc_long_cd=0313113109&wrk_plc_long_cd=0313113110&wrk_plc_long_cd=0313113112&wrk_plc_long_cd=0313113113&wrk_plc_long_cd=0313113114&wrk_plc_long_cd=0313113115&wrk_plc_long_cd=0313113116&wrk_plc_long_cd=0313113117&wrk_plc_long_cd=0313113118&wrk_plc_long_cd=0313113119&wrk_plc_long_cd=0313113120&wrk_plc_long_cd=0313113121&wrk_plc_long_cd=0313113122&wrk_plc_long_cd=0313113123&employ_frm_cd=01'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 各求人情報を取得\n",
    "        job_elements = soup.select(\"li.rnn-jobOfferList__item\")\n",
    "        total_jobs = len(job_elements)\n",
    "\n",
    "        # 各求人情報をループ\n",
    "        for job_element in tqdm(job_elements, total=total_jobs, desc=f\"Processing page {page_number} jobs\", leave=False):\n",
    "            # 各情報を取得\n",
    "            title = job_element.select_one(\"h2.rnn-textLl.js-abScreen__title\").text.strip()\n",
    "\n",
    "            try:\n",
    "                income_details = job_element.select_one(\"tr.js-abScreen__income td.rnn-offerDetail__text\").text.strip()\n",
    "                income_details_cleaned = ' '.join(income_details.split())\n",
    "            except:\n",
    "                income_details_cleaned = ''\n",
    "\n",
    "            try:\n",
    "                requirements = job_element.select_one(\"tr.js-abScreen__prefer td.rnn-offerDetail__text\").text.strip()\n",
    "            except:\n",
    "                requirements = ''\n",
    "\n",
    "            # 詳細ページのリンクを取得\n",
    "            link = job_element.select_one(\"a.rnn-linkText.rnn-linkText--black\")['href']\n",
    "            details_url = f'https://next.rikunabi.com{link}'\n",
    "            details_response = requests.get(details_url)\n",
    "            details_soup = BeautifulSoup(details_response.content, 'html.parser')\n",
    "\n",
    "            # 「リクルートエージェントからの求人」が含まれているか確認\n",
    "            if 'リクルートエージェントからの求人' in details_soup.get_text():\n",
    "                company_name = details_soup.select_one('p.rnn-offerCompanyName').text.strip()\n",
    "\n",
    "                table_rows = details_soup.select('table.rnn-detailTable tr.rnn-tableGrid')\n",
    "\n",
    "                def get_value_from_table(row_title):\n",
    "                    for row in table_rows:\n",
    "                        th_element = row.select_one('th')\n",
    "                        if th_element and th_element.text.strip() == row_title:\n",
    "                            td_element = row.select_one('td')\n",
    "                            return td_element.text.strip() if td_element else ''\n",
    "                    return ''\n",
    "\n",
    "                ceo_name = get_value_from_table('代表者')\n",
    "                headquarters_location = get_value_from_table('事業所')\n",
    "                industry_heading = get_value_from_table('業種')\n",
    "\n",
    "            else:\n",
    "                syosai_elements = details_soup.find_all('span', class_='rn3-companyOfferTabMenu__navItemText')\n",
    "\n",
    "                if len(syosai_elements) == 2:\n",
    "                    # URLの/nx1の部分を/nx2に変更\n",
    "                    modified_url = details_url.replace('/nx1', '/nx2')\n",
    "                    # 変更後のURLにアクセス\n",
    "                    response = requests.get(modified_url)\n",
    "                    details_soup = BeautifulSoup(response.content, 'html.parser')  # ここを修正\n",
    "                    details_url = modified_url\n",
    "                    \n",
    "                company_info = details_soup.select_one('div.rn3-companyOfferCompany')\n",
    "\n",
    "                try:\n",
    "                    company_name = company_info.find('h3', string='社名').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    company_name = ''\n",
    "\n",
    "                try:\n",
    "                    ceo_name = company_info.find('h3', string='代表者').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    ceo_name = ''\n",
    "\n",
    "                try:\n",
    "                    headquarters_location = company_info.find('h3', string='本社所在地').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    headquarters_location = ''\n",
    "\n",
    "                try:\n",
    "                    industry_headings = company_info.find('h3', string='業種').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                    parts = industry_headings.split('/')\n",
    "                    industry_heading = parts[0].replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    industry_heading = ''\n",
    "\n",
    "                try:\n",
    "                    contact_heading = details_soup.find('h3', class_='rn3-companyOfferEntry__heading', string='連絡先')\n",
    "                    contact_info_div = contact_heading.find_next_sibling('div')\n",
    "                    contact_info_text = contact_info_div.get_text(separator='\\n', strip=True)\n",
    "                    contact_info_text = contact_info_text.replace('\\xa0', ' ')\n",
    "                    contact_info_text = ' '.join(contact_info_text.split())\n",
    "                    page = contact_info_div.find('a')\n",
    "                    url = 'https://next.rikunabi.com/' + page['href']\n",
    "                except:\n",
    "                    url = ''\n",
    "                    contact_info_text = ''\n",
    "\n",
    "            # リストに情報を追加\n",
    "            job_title.append(title)\n",
    "            unit_price.append(income_details_cleaned)\n",
    "            required_experience.append(requirements)\n",
    "            details_page_link.append(details_url)\n",
    "            representative_name.append(ceo_name)\n",
    "            headquarters_locations.append(headquarters_location)\n",
    "            industry.append(industry_heading)\n",
    "            contact_number.append(contact_info_text)\n",
    "            company_info_link.append(url)\n",
    "\n",
    "            data = {\n",
    "                \"job_title\": title,\n",
    "                \"company_name\": company_name,\n",
    "                \"contact_number\": contact_info_text,\n",
    "                \"industry\": industry_heading,\n",
    "                \"representative_name\": ceo_name,\n",
    "                \"company_info_link\": url,\n",
    "                \"unit_price\": income_details_cleaned,\n",
    "                \"headquarters_location\": headquarters_location,\n",
    "                \"qualification\": '',  # qualification の情報がどこにあるかによって変更\n",
    "                \"required_experience\": requirements,\n",
    "                \"details_page_link\": details_url,\n",
    "                \"contact_url\": url\n",
    "            }\n",
    "\n",
    "            all_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_number}: {e}\")\n",
    "        continue\n",
    "\n",
    "# データフレームに変換\n",
    "df1 = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de4ef183-5405-4784-b25d-4e3df256e83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.to_csv('test.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80f613c-be07-4852-9270-d429e1d075b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Processing page 1 jobs:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Processing page 1 jobs:   2%|▏         | 1/50 [00:00<00:20,  2.44it/s]\u001b[A\n",
      "Processing page 1 jobs:   4%|▍         | 2/50 [00:00<00:20,  2.32it/s]\u001b[A\n",
      "Processing page 1 jobs:   6%|▌         | 3/50 [00:01<00:21,  2.17it/s]\u001b[A\n",
      "Processing page 1 jobs:   8%|▊         | 4/50 [00:02<00:39,  1.15it/s]\u001b[A\n",
      "Processing page 1 jobs:  10%|█         | 5/50 [00:03<00:31,  1.44it/s]\u001b[A\n",
      "Processing page 1 jobs:  12%|█▏        | 6/50 [00:03<00:26,  1.64it/s]\u001b[A\n",
      "Processing page 1 jobs:  14%|█▍        | 7/50 [00:04<00:23,  1.83it/s]\u001b[A\n",
      "Processing page 1 jobs:  16%|█▌        | 8/50 [00:04<00:20,  2.04it/s]\u001b[A\n",
      "Processing page 1 jobs:  18%|█▊        | 9/50 [00:04<00:19,  2.07it/s]\u001b[A\n",
      "Processing page 1 jobs:  20%|██        | 10/50 [00:05<00:19,  2.09it/s]\u001b[A\n",
      "Processing page 1 jobs:  22%|██▏       | 11/50 [00:05<00:18,  2.14it/s]\u001b[A\n",
      "Processing page 1 jobs:  24%|██▍       | 12/50 [00:06<00:17,  2.15it/s]\u001b[A\n",
      "Processing page 1 jobs:  26%|██▌       | 13/50 [00:06<00:17,  2.11it/s]\u001b[A\n",
      "Processing page 1 jobs:  28%|██▊       | 14/50 [00:07<00:17,  2.04it/s]\u001b[A\n",
      "Processing page 1 jobs:  30%|███       | 15/50 [00:07<00:16,  2.14it/s]\u001b[A\n",
      "Processing page 1 jobs:  32%|███▏      | 16/50 [00:08<00:15,  2.15it/s]\u001b[A\n",
      "Processing page 1 jobs:  34%|███▍      | 17/50 [00:08<00:14,  2.20it/s]\u001b[A\n",
      "Processing page 1 jobs:  36%|███▌      | 18/50 [00:09<00:14,  2.20it/s]\u001b[A\n",
      "Processing page 1 jobs:  38%|███▊      | 19/50 [00:09<00:14,  2.17it/s]\u001b[A\n",
      "Processing page 1 jobs:  40%|████      | 20/50 [00:10<00:13,  2.18it/s]\u001b[A\n",
      "Processing page 1 jobs:  42%|████▏     | 21/50 [00:10<00:13,  2.12it/s]\u001b[A\n",
      "Processing page 1 jobs:  44%|████▍     | 22/50 [00:10<00:12,  2.20it/s]\u001b[A\n",
      "Processing page 1 jobs:  46%|████▌     | 23/50 [00:11<00:11,  2.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  48%|████▊     | 24/50 [00:11<00:11,  2.28it/s]\u001b[A\n",
      "Processing page 1 jobs:  50%|█████     | 25/50 [00:12<00:11,  2.23it/s]\u001b[A\n",
      "Processing page 1 jobs:  52%|█████▏    | 26/50 [00:12<00:10,  2.21it/s]\u001b[A\n",
      "Processing page 1 jobs:  54%|█████▍    | 27/50 [00:13<00:10,  2.19it/s]\u001b[A\n",
      "Processing page 1 jobs:  56%|█████▌    | 28/50 [00:13<00:09,  2.24it/s]\u001b[A\n",
      "Processing page 1 jobs:  58%|█████▊    | 29/50 [00:13<00:09,  2.33it/s]\u001b[A\n",
      "Processing page 1 jobs:  60%|██████    | 30/50 [00:14<00:08,  2.26it/s]\u001b[A\n",
      "Processing page 1 jobs:  62%|██████▏   | 31/50 [00:14<00:07,  2.39it/s]\u001b[A\n",
      "Processing page 1 jobs:  64%|██████▍   | 32/50 [00:15<00:07,  2.45it/s]\u001b[A\n",
      "Processing page 1 jobs:  66%|██████▌   | 33/50 [00:15<00:06,  2.48it/s]\u001b[A\n",
      "Processing page 1 jobs:  68%|██████▊   | 34/50 [00:15<00:06,  2.50it/s]\u001b[A\n",
      "Processing page 1 jobs:  70%|███████   | 35/50 [00:16<00:06,  2.46it/s]\u001b[A\n",
      "Processing page 1 jobs:  72%|███████▏  | 36/50 [00:16<00:05,  2.46it/s]\u001b[A\n",
      "Processing page 1 jobs:  74%|███████▍  | 37/50 [00:17<00:05,  2.47it/s]\u001b[A\n",
      "Processing page 1 jobs:  76%|███████▌  | 38/50 [00:17<00:04,  2.50it/s]\u001b[A\n",
      "Processing page 1 jobs:  78%|███████▊  | 39/50 [00:18<00:05,  2.12it/s]\u001b[A\n",
      "Processing page 1 jobs:  80%|████████  | 40/50 [00:18<00:04,  2.13it/s]\u001b[A\n",
      "Processing page 1 jobs:  82%|████████▏ | 41/50 [00:19<00:04,  2.16it/s]\u001b[A\n",
      "Processing page 1 jobs:  84%|████████▍ | 42/50 [00:19<00:03,  2.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  86%|████████▌ | 43/50 [00:19<00:03,  2.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  88%|████████▊ | 44/50 [00:20<00:02,  2.27it/s]\u001b[A\n",
      "Processing page 1 jobs:  90%|█████████ | 45/50 [00:20<00:02,  2.28it/s]\u001b[A\n",
      "Processing page 1 jobs:  92%|█████████▏| 46/50 [00:21<00:01,  2.36it/s]\u001b[A\n",
      "Processing page 1 jobs:  94%|█████████▍| 47/50 [00:21<00:01,  2.35it/s]\u001b[A\n",
      "Processing page 1 jobs:  96%|█████████▌| 48/50 [00:22<00:00,  2.38it/s]\u001b[A\n",
      "Processing page 1 jobs:  98%|█████████▊| 49/50 [00:22<00:00,  2.44it/s]\u001b[A\n",
      "Processing page 1 jobs: 100%|██████████| 50/50 [00:22<00:00,  2.50it/s]\u001b[A\n",
      "Processing pages:  50%|█████     | 1/2 [00:24<00:24, 24.47s/it]        \u001b[A\n",
      "Processing page 2 jobs:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Processing page 2 jobs:   2%|▏         | 1/50 [00:00<00:26,  1.83it/s]\u001b[A\n",
      "Processing page 2 jobs:   4%|▍         | 2/50 [00:01<00:28,  1.70it/s]\u001b[A\n",
      "Processing page 2 jobs:   6%|▌         | 3/50 [00:01<00:28,  1.67it/s]\u001b[A\n",
      "Processing page 2 jobs:   8%|▊         | 4/50 [00:02<00:28,  1.60it/s]\u001b[A\n",
      "Processing page 2 jobs:  10%|█         | 5/50 [00:02<00:25,  1.76it/s]\u001b[A\n",
      "Processing page 2 jobs:  12%|█▏        | 6/50 [00:03<00:23,  1.91it/s]\u001b[A\n",
      "Processing page 2 jobs:  14%|█▍        | 7/50 [00:03<00:23,  1.83it/s]\u001b[A\n",
      "Processing page 2 jobs:  16%|█▌        | 8/50 [00:04<00:23,  1.77it/s]\u001b[A\n",
      "Processing page 2 jobs:  18%|█▊        | 9/50 [00:05<00:23,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  20%|██        | 10/50 [00:05<00:22,  1.82it/s]\u001b[A\n",
      "Processing page 2 jobs:  22%|██▏       | 11/50 [00:06<00:21,  1.82it/s]\u001b[A\n",
      "Processing page 2 jobs:  24%|██▍       | 12/50 [00:06<00:22,  1.67it/s]\u001b[A\n",
      "Processing page 2 jobs:  26%|██▌       | 13/50 [00:07<00:21,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  28%|██▊       | 14/50 [00:07<00:18,  1.93it/s]\u001b[A\n",
      "Processing page 2 jobs:  30%|███       | 15/50 [00:08<00:19,  1.80it/s]\u001b[A\n",
      "Processing page 2 jobs:  32%|███▏      | 16/50 [00:09<00:19,  1.74it/s]\u001b[A\n",
      "Processing page 2 jobs:  34%|███▍      | 17/50 [00:09<00:19,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  36%|███▌      | 18/50 [00:10<00:17,  1.85it/s]\u001b[A\n",
      "Processing page 2 jobs:  38%|███▊      | 19/50 [00:10<00:18,  1.70it/s]\u001b[A\n",
      "Processing page 2 jobs:  40%|████      | 20/50 [00:11<00:17,  1.74it/s]\u001b[A\n",
      "Processing page 2 jobs:  42%|████▏     | 21/50 [00:12<00:17,  1.66it/s]\u001b[A\n",
      "Processing page 2 jobs:  44%|████▍     | 22/50 [00:12<00:15,  1.83it/s]\u001b[A\n",
      "Processing page 2 jobs:  46%|████▌     | 23/50 [00:13<00:15,  1.77it/s]\u001b[A\n",
      "Processing page 2 jobs:  48%|████▊     | 24/50 [00:13<00:15,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  50%|█████     | 25/50 [00:14<00:15,  1.61it/s]\u001b[A\n",
      "Processing page 2 jobs:  52%|█████▏    | 26/50 [00:14<00:14,  1.67it/s]\u001b[A\n",
      "Processing page 2 jobs:  54%|█████▍    | 27/50 [00:15<00:13,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs:  56%|█████▌    | 28/50 [00:16<00:13,  1.60it/s]\u001b[A\n",
      "Processing page 2 jobs:  58%|█████▊    | 29/50 [00:16<00:12,  1.62it/s]\u001b[A\n",
      "Processing page 2 jobs:  60%|██████    | 30/50 [00:17<00:11,  1.76it/s]\u001b[A\n",
      "Processing page 2 jobs:  62%|██████▏   | 31/50 [00:17<00:11,  1.71it/s]\u001b[A\n",
      "Processing page 2 jobs:  64%|██████▍   | 32/50 [00:18<00:10,  1.71it/s]\u001b[A\n",
      "Processing page 2 jobs:  66%|██████▌   | 33/50 [00:19<00:10,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs:  68%|██████▊   | 34/50 [00:19<00:08,  1.86it/s]\u001b[A\n",
      "Processing page 2 jobs:  70%|███████   | 35/50 [00:20<00:08,  1.69it/s]\u001b[A\n",
      "Processing page 2 jobs:  72%|███████▏  | 36/50 [00:20<00:08,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs:  74%|███████▍  | 37/50 [00:21<00:07,  1.66it/s]\u001b[A\n",
      "Processing page 2 jobs:  76%|███████▌  | 38/50 [00:21<00:06,  1.77it/s]\u001b[A\n",
      "Processing page 2 jobs:  78%|███████▊  | 39/50 [00:22<00:06,  1.70it/s]\u001b[A\n",
      "Processing page 2 jobs:  80%|████████  | 40/50 [00:23<00:05,  1.76it/s]\u001b[A\n",
      "Processing page 2 jobs:  82%|████████▏ | 41/50 [00:23<00:05,  1.63it/s]\u001b[A\n",
      "Processing page 2 jobs:  84%|████████▍ | 42/50 [00:24<00:04,  1.78it/s]\u001b[A\n",
      "Processing page 2 jobs:  86%|████████▌ | 43/50 [00:24<00:03,  1.76it/s]\u001b[A\n",
      "Processing page 2 jobs:  88%|████████▊ | 44/50 [00:25<00:03,  1.72it/s]\u001b[A\n",
      "Processing page 2 jobs:  90%|█████████ | 45/50 [00:26<00:02,  1.69it/s]\u001b[A\n",
      "Processing page 2 jobs:  92%|█████████▏| 46/50 [00:26<00:02,  1.67it/s]\u001b[A\n",
      "Processing page 2 jobs:  94%|█████████▍| 47/50 [00:27<00:01,  1.75it/s]\u001b[A\n",
      "Processing page 2 jobs:  96%|█████████▌| 48/50 [00:27<00:01,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs:  98%|█████████▊| 49/50 [00:28<00:00,  1.68it/s]\u001b[A\n",
      "Processing page 2 jobs: 100%|██████████| 50/50 [00:29<00:00,  1.68it/s]\u001b[A\n",
      "Processing pages: 100%|██████████| 2/2 [00:55<00:00, 27.78s/it]        \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                job_title company_name contact_number  \\\n",
      "0          【還元率80％超】上場G・案件選択可・年休130｜SE・PG                               \n",
      "1           未経験歓迎＊新しい一歩をサポート◎IT関連事務・PG/s3                               \n",
      "2          上場グループ・前給保証・案件選択可・年休130日｜SE・PG                               \n",
      "3          未経験から安心！充実研修あり【ITエンジニア】残業12.8h                               \n",
      "4          創りたい！が自社で作れるゲームエンジニアへ（IT・Web等）                               \n",
      "..                                    ...          ...            ...   \n",
      "95                          ゲームエンジニア・テスター   株式会社ZOSTEC                  \n",
      "96               【ホワイトハッカー】未経験育成・正社員・専門研修     株式会社ジェーン                  \n",
      "97   \\\\ 未経験育成//【ITエンジニア】　正社員/研修あり　完全在宅も叶う      株式会社ミクス                  \n",
      "98                                ITエンジニア     株式会社ソリット                  \n",
      "99  【北千住】最先端AIエンジニア//Python//スクール研修//未経験可     (株)AIベース                  \n",
      "\n",
      "   industry representative_name company_info_link  \\\n",
      "0                                                   \n",
      "1                                                   \n",
      "2                                                   \n",
      "3                                                   \n",
      "4                                                   \n",
      "..      ...                 ...               ...   \n",
      "95                         北村琢真                     \n",
      "96                        佐藤 雄大                     \n",
      "97                        中村 翔悟                     \n",
      "98                        前田 清太                     \n",
      "99                        山本 太郎                     \n",
      "\n",
      "                                           unit_price  \\\n",
      "0   670万円／経験7年（（月給55万円）※年収210万円UPの実績あり）450万円／経験3年（...   \n",
      "1   520万円／技術経験年数7年（月給29万円＋残業手当＋諸手当＋賞与）420万円／技術経験年数...   \n",
      "2   670万円／経験7年（月給55万円 ※年収210万円UPの実績あり）450万円／経験3年（月...   \n",
      "3   600万円／未経験から入社して6年目 34歳（月給40万円＋賞与）510万円／未経験から入社...   \n",
      "4   550万円／経験3年・29歳（前職：飲食ホールスタッフ）／SE（月給45.8万円）1010万...   \n",
      "..                                                ...   \n",
      "95  給与例 【年収例】 ・510万円／未経験入社4年・30歳（月給38万円＋賞与） ・400万円...   \n",
      "96                                                      \n",
      "97                                                      \n",
      "98                                                      \n",
      "99                                                      \n",
      "\n",
      "                   headquarters_location qualification  \\\n",
      "0                                                        \n",
      "1                                                        \n",
      "2                                                        \n",
      "3                                                        \n",
      "4                                                        \n",
      "..                                   ...           ...   \n",
      "95                   東京都渋谷区桜丘町21-2池田ビル6階                 \n",
      "96  1120002 東京都文京区小石川3-17-20ブランコート文京竹早02                 \n",
      "97                 1300013 東京都墨田区錦糸1-2-1                 \n",
      "98              1120004 東京都文京区後楽2丁目3番11号                 \n",
      "99           1100012 東京都台東区竜泉3丁目5番1号-501                 \n",
      "\n",
      "                                  required_experience  \\\n",
      "0        ＼経験年数・年齢・学歴不問／★何らかの開発経験又はインフラ経験がある方　★人柄重視の採用   \n",
      "1   ＜在宅勤務実績有＞◆未経験歓迎◆既卒・第二新卒歓迎◆安定環境で働きたい方◆新しい活躍の場を見...   \n",
      "2       年齢・学歴不問！★何かしらの開発orインフラ経験がある方　★人柄重視！リモート・副業OK！   \n",
      "3          学歴不問／経験者歓迎／ITスクールや大学、専門学校、独学で学んでいた方も歓迎します！   \n",
      "4   第二新卒OK＊未経験歓迎♪学歴、社会人経験は問いません★異業種入社85%★経験者は【高待遇枠...   \n",
      "..                                                ...   \n",
      "95  求めている人材 30歳以下の方（長期キャリア形成のため）  ・学歴不問 （高卒、専門卒、短大...   \n",
      "96  求める人材:  ★未経験・第二新卒・社会人経験のない方歓迎！ ★Web業界経験のない方も大歓...   \n",
      "97  求める人材:  「履歴書に自信がなくても大丈夫！」  ★やる気さえあればご応募OK★ お人柄...   \n",
      "98  求める人材:  お人柄重視の採用です！  【面接は2回のみ！】※すべてオンライン面接です！ ...   \n",
      "99  求める人材:  ITの経験がなくても、新しいことに挑戦し、  積極的に学び続ける意欲がある方...   \n",
      "\n",
      "                                    details_page_link contact_url  \n",
      "0   https://next.rikunabi.com/company/cmi429130500...              \n",
      "1   https://next.rikunabi.com/company/cmi263557402...              \n",
      "2   https://next.rikunabi.com/company/cmi429130200...              \n",
      "3   https://next.rikunabi.com/company/cmi015966306...              \n",
      "4   https://next.rikunabi.com/company/cmi433762100...              \n",
      "..                                                ...         ...  \n",
      "95  https://next.rikunabi.com/viewjob/jk12391076eb...              \n",
      "96  https://next.rikunabi.com/viewjob/jkef002014d1...              \n",
      "97  https://next.rikunabi.com/viewjob/jk1c4049d2af...              \n",
      "98  https://next.rikunabi.com/viewjob/jk11606d1493...              \n",
      "99  https://next.rikunabi.com/viewjob/jk437f22f134...              \n",
      "\n",
      "[100 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# データを保存するリスト\n",
    "job_title = []\n",
    "unit_price = []\n",
    "required_experience = []\n",
    "details_page_link = []\n",
    "representative_name = []\n",
    "headquarters_locations = []\n",
    "industry = []\n",
    "contact_number = []\n",
    "company_info_link = []\n",
    "all_data = []\n",
    "\n",
    "# ページ番号を1から96までループ\n",
    "for page_number in tqdm(range(1, 3), desc=\"Processing pages\"):\n",
    "    try:\n",
    "        url = f'https://next.rikunabi.com/rnc/docs/cp_s00700.jsp?page={page_number}&cur=ACgAAQAoAAAAAAAAAAAAAAACMT4N4gECAQkUBgU6vVJcMq7CpmpPjbzo3HJe4dF7UXdwgM%2BXoqqxn4oQb50yRo6ag3iAKyyeqyFDcEzcwkGZDsn8prbqAeX62tWArTu1z3hoh%2FE%3D&cur_p=2&occupation_cd=EHPW9&wrk_plc_long_cd=0313113103&wrk_plc_long_cd=0313113105&wrk_plc_long_cd=0313113106&wrk_plc_long_cd=0313113107&wrk_plc_long_cd=0313113108&wrk_plc_long_cd=0313113109&wrk_plc_long_cd=0313113110&wrk_plc_long_cd=0313113112&wrk_plc_long_cd=0313113113&wrk_plc_long_cd=0313113114&wrk_plc_long_cd=0313113115&wrk_plc_long_cd=0313113116&wrk_plc_long_cd=0313113117&wrk_plc_long_cd=0313113118&wrk_plc_long_cd=0313113119&wrk_plc_long_cd=0313113120&wrk_plc_long_cd=0313113121&wrk_plc_long_cd=0313113122&wrk_plc_long_cd=0313113123&employ_frm_cd=01'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 各求人情報を取得\n",
    "        job_elements = soup.select(\"li.rnn-jobOfferList__item\")\n",
    "        total_jobs = len(job_elements)\n",
    "\n",
    "        # 各求人情報をループ\n",
    "        for job_element in tqdm(job_elements, total=total_jobs, desc=f\"Processing page {page_number} jobs\", leave=False):\n",
    "            # 各情報を取得\n",
    "            title = job_element.select_one(\"h2.rnn-textLl.js-abScreen__title\").text.strip()\n",
    "\n",
    "            try:\n",
    "                income_details = job_element.select_one(\"tr.js-abScreen__income td.rnn-offerDetail__text\").text.strip()\n",
    "                income_details_cleaned = ' '.join(income_details.split())\n",
    "            except:\n",
    "                income_details_cleaned = ''\n",
    "\n",
    "            try:\n",
    "                requirements = job_element.select_one(\"tr.js-abScreen__prefer td.rnn-offerDetail__text\").text.strip()\n",
    "            except:\n",
    "                requirements = ''\n",
    "\n",
    "            # 詳細ページのリンクを取得\n",
    "            link = job_element.select_one(\"a.rnn-linkText.rnn-linkText--black\")['href']\n",
    "            details_url = f'https://next.rikunabi.com{link}'\n",
    "            details_response = requests.get(details_url)\n",
    "            \n",
    "            \n",
    "            details_soup = BeautifulSoup(details_response.content, 'html.parser')\n",
    "            \n",
    "            if \n",
    "\n",
    "            # 「リクルートエージェントからの求人」が含まれているか確認\n",
    "            if 'リクルートエージェントからの求人' in details_soup.get_text():\n",
    "                company_name = details_soup.select_one('p.rnn-offerCompanyName').text.strip()\n",
    "\n",
    "                table_rows = details_soup.select('table.rnn-detailTable tr.rnn-tableGrid')\n",
    "\n",
    "                def get_value_from_table(row_title):\n",
    "                    for row in table_rows:\n",
    "                        th_element = row.select_one('th')\n",
    "                        if th_element.text.strip() == row_title:\n",
    "                            td_element = row.select_one('td')\n",
    "                            return td_element.text.strip()\n",
    "                    return ''\n",
    "\n",
    "                ceo_name = get_value_from_table('代表者')\n",
    "                headquarters_location = get_value_from_table('事業所')\n",
    "                industry_heading = get_value_from_table('業種')\n",
    "\n",
    "            else:\n",
    "                \n",
    "                syosai_elements = details_soup.find_all('span', class_='rn3-companyOfferTabMenu__navItemText')\n",
    "\n",
    "                if len(syosai_elements) == 2:\n",
    "                # URLの/nx1の部分を/nx2に変更\n",
    "                    original_url = \"https://next.rikunabi.com/company/cmi4259035001/nx1_rq0027219998/?list_disp_no=9&jrtk=5-nrt1-0-1i62insqgh9f3800-PPP0027219998%252D0627027213&refnum=0027219998-0627027213&leadtc=n_ichiran_cst_n5_ttl\"\n",
    "                    modified_url = original_url.replace('/nx1', '/nx2')\n",
    "                    # 変更後のURLにアクセス\n",
    "                    response = requests.get(modified_url)\n",
    "                    details_soup = BeautifulSoup(details_response.content, 'html.parser')\n",
    "\n",
    "                \n",
    "                company_info = details_soup.select_one('div.rn3-companyOfferCompany')\n",
    "\n",
    "                try:\n",
    "                    company_name = company_info.find('h3', string='社名').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    company_name = ''\n",
    "\n",
    "                try:\n",
    "                    ceo_name = company_info.find('h3', string='代表者').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    ceo_name = ''\n",
    "\n",
    "                try:\n",
    "                    headquarters_location = company_info.find('h3', string='本社所在地').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    headquarters_location = ''\n",
    "\n",
    "                try:\n",
    "                    industry_headings = company_info.find('h3', string='業種').find_next_sibling('p', class_='rn3-companyOfferCompany__text').get_text(strip=True).replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                    parts = industry_headings.split('/')\n",
    "                    industry_heading = parts[0].replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "                except:\n",
    "                    industry_heading = ''\n",
    "\n",
    "                try:\n",
    "                    contact_heading = details_soup.find('h3', class_='rn3-companyOfferEntry__heading', string='連絡先')\n",
    "                    contact_info_div = contact_heading.find_next_sibling('div')\n",
    "                    contact_info_text = contact_info_div.get_text(separator='\\n', strip=True)\n",
    "                    contact_info_text = contact_info_text.replace('\\xa0', ' ')\n",
    "                    contact_info_text = ' '.join(contact_info_text.split())\n",
    "                    page = contact_info_div.find('a')\n",
    "                    url = 'https://next.rikunabi.com/' + page['href']\n",
    "                except:\n",
    "                    url = ''\n",
    "                    contact_info_text = ''\n",
    "\n",
    "            # リストに情報を追加\n",
    "            job_title.append(title)\n",
    "            unit_price.append(income_details_cleaned)\n",
    "            required_experience.append(requirements)\n",
    "            details_page_link.append(details_url)\n",
    "            representative_name.append(ceo_name)\n",
    "            headquarters_locations.append(headquarters_location)\n",
    "            industry.append(industry_heading)\n",
    "            contact_number.append(contact_info_text)\n",
    "            company_info_link.append(url)\n",
    "\n",
    "            data = {\n",
    "                \"job_title\": title,\n",
    "                \"company_name\": company_name,\n",
    "                \"contact_number\": contact_info_text,\n",
    "                \"industry\": industry_heading,\n",
    "                \"representative_name\": ceo_name,\n",
    "                \"company_info_link\": url,\n",
    "                \"unit_price\": income_details_cleaned,\n",
    "                \"headquarters_location\": headquarters_location,\n",
    "                \"qualification\": '',  # qualification の情報がどこにあるかによって変更\n",
    "                \"required_experience\": requirements,\n",
    "                \"details_page_link\": details_url,\n",
    "                \"contact_url\": url\n",
    "            }\n",
    "\n",
    "            all_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_number}: {e}\")\n",
    "        continue\n",
    "\n",
    "# データフレームに変換\n",
    "df1 = pd.DataFrame(all_data)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a9ddb6c-caa4-4c67-8209-28a8a7bd7918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = f'https://next.rikunabi.com/company/cmi3109485001/nx1_rq0027227217/?list_disp_no=33&jrtk=5-nrt1-0-1i62insqgh9f3800-PPP0027227217%252D0313113103&refnum=0027227217-0313113103&leadtc=n_ichiran_cst_n4_ttl'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08276dc1-ddfc-40e5-bdf2-3daee2aba3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要素が2つではありません。要素の数: 1\n"
     ]
    }
   ],
   "source": [
    "syosai_elements = soup.find_all('span', class_='rn3-companyOfferTabMenu__navItemText')\n",
    "\n",
    "if len(syosai_elements) == 2:\n",
    "    # 要素が2つある場合の処理 (A)\n",
    "    syosai_texts = [element.text for element in syosai_elements]\n",
    "    # 例: 取得したテキストを表示\n",
    "    print(\"要素が2つあります:\", syosai_texts)\n",
    "else:\n",
    "    # 要素が2つでない場合の処理 (B)\n",
    "    # 例: エラーメッセージを表示\n",
    "    print(\"要素が2つではありません。要素の数:\", len(syosai_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a3be32d-3c84-4a17-986f-7dadd61a014f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['企業からのメッセージ', '求人情報']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syosai_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c3bc2-d2da-430f-8da7-5d668179a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(syosai_elements) == 2:\n",
    "    # URLの/nx1の部分を/nx2に変更\n",
    "    original_url = \"https://next.rikunabi.com/company/cmi4259035001/nx1_rq0027219998/?list_disp_no=9&jrtk=5-nrt1-0-1i62insqgh9f3800-PPP0027219998%252D0627027213&refnum=0027219998-0627027213&leadtc=n_ichiran_cst_n5_ttl\"\n",
    "    modified_url = original_url.replace('/nx1', '/nx2')\n",
    "    print(\"Modified URL:\", modified_url)\n",
    "    \n",
    "    # 変更後のURLにアクセス\n",
    "    response = requests.get(modified_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
